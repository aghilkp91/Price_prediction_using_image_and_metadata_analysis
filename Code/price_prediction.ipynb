{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.image import imread\n",
    "from skimage import data as skim_data \n",
    "from skimage import io, color, exposure\n",
    "from skimage.transform import resize, rescale, rotate, setup, warp, AffineTransform\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import csv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract and Save Features ##\n",
    "\n",
    "We run the dataset through VGG-16, extracting the activations of the last feature layer as our high-dimensional feature vectors. We then reduce the dimensionality using PCA."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from skimage.feature import hog\n",
    "data_path = \"../Data/\"\n",
    "\n",
    "im_prices = np.zeros(7674)\n",
    "images = []\n",
    "with open(data_path + \"updated_ecommerce_data.csv\", \"r\") as file:\n",
    "    counter = -1\n",
    "    for line in file:\n",
    "        if counter == -1:\n",
    "            counter += 1\n",
    "            continue\n",
    "        line_arr = line.split(',')\n",
    "        img_path = data_path + 'Images/' + line_arr[1]+ '_0' + '.jpg'\n",
    "        img_file = imread(img_path)\n",
    "        curr_im = color.rgb2gray(img_file)\n",
    "        im_prices[counter] = int(line_arr[4])\n",
    "        counter+=1\n",
    "        images.append(curr_im)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/Images/cc51c3dd925d9d84e2fb28c7918dbbc3_0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/44/zdx95fpn3bv669w81970ks_w0000gn/T/ipykernel_94045/2627425249.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0mline_arr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m','\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mimg_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata_path\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'Images/'\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mline_arr\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m+\u001B[0m \u001B[0;34m'_0'\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'.jpg'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0mimg_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m         \u001B[0mcurr_im\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcolor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrgb2gray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mim_prices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcounter\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline_arr\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Aghil/Radboud/Thesis/Codes/Price_regression_using_CBIR/.venv/lib/python3.8/site-packages/matplotlib/image.py\u001B[0m in \u001B[0;36mimread\u001B[0;34m(fname, format)\u001B[0m\n\u001B[1;32m   1499\u001B[0m                     \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBytesIO\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1500\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mimread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformat\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1501\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0mimg_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1502\u001B[0m         return (_pil_png_to_float_array(image)\n\u001B[1;32m   1503\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mPIL\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPngImagePlugin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPngImageFile\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Aghil/Radboud/Thesis/Codes/Price_regression_using_CBIR/.venv/lib/python3.8/site-packages/PIL/Image.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(fp, mode, formats)\u001B[0m\n\u001B[1;32m   2966\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2967\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2968\u001B[0;31m         \u001B[0mfp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbuiltins\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2969\u001B[0m         \u001B[0mexclusive_fp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2970\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../Data/Images/cc51c3dd925d9d84e2fb28c7918dbbc3_0.jpg'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "hog_array = np.zeros((len(images), 224*224))\n",
    "print(\"hogarray\")\n",
    "print(hog_array)\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    fd, hog_image = hog(image, orientations=8, pixels_per_cell=(32, 32),\n",
    "                        cells_per_block=(1, 1), visualise=True, block_norm='L2-Hys')\n",
    "    flattened_len = int(hog_image.shape[0]) * int(hog_image.shape[1])\n",
    "    pixels = np.reshape(hog_image, (-1, flattened_len))\n",
    "    hog_array[i, :] = pixels\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(hog_array)\n",
    "hog_images_compressed = pca.transform(hog_array)\n",
    "print(hog_images_compressed)\n",
    "\n",
    "pca = PCA(n_components=200)\n",
    "pca.fit(hog_array)\n",
    "hog_images_compressed = pca.transform(hog_array)\n",
    "\n",
    "np.save(\"ecommerce_linreg_hog_pca_features\", hog_images_compressed)\n",
    "np.save(\"ecommerce_linreg_hog_pca_components\", pca.components_)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hogarray\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 50176)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/44/zdx95fpn3bv669w81970ks_w0000gn/T/ipykernel_94045/2775898809.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0mpca\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPCA\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_components\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m \u001B[0mpca\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhog_array\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m \u001B[0mhog_images_compressed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpca\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhog_array\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhog_images_compressed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Aghil/Radboud/Thesis/Codes/Price_regression_using_CBIR/.venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    357\u001B[0m             \u001B[0mReturns\u001B[0m \u001B[0mthe\u001B[0m \u001B[0minstance\u001B[0m \u001B[0mitself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    358\u001B[0m         \"\"\"\n\u001B[0;32m--> 359\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    360\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    361\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Aghil/Radboud/Thesis/Codes/Price_regression_using_CBIR/.venv/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001B[0m in \u001B[0;36m_fit\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    402\u001B[0m                             'TruncatedSVD for a possible alternative.')\n\u001B[1;32m    403\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 404\u001B[0;31m         X = self._validate_data(X, dtype=[np.float64, np.float32],\n\u001B[0m\u001B[1;32m    405\u001B[0m                                 ensure_2d=True, copy=self.copy)\n\u001B[1;32m    406\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Aghil/Radboud/Thesis/Codes/Price_regression_using_CBIR/.venv/lib/python3.8/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    419\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    420\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'no_validation'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 421\u001B[0;31m             \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    422\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    423\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Aghil/Radboud/Thesis/Codes/Price_regression_using_CBIR/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Aghil/Radboud/Thesis/Codes/Price_regression_using_CBIR/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[1;32m    724\u001B[0m         \u001B[0mn_samples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    725\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mn_samples\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mensure_min_samples\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 726\u001B[0;31m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001B[0m\u001B[1;32m    727\u001B[0m                              \u001B[0;34m\" minimum of %d is required%s.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    728\u001B[0m                              % (n_samples, array.shape, ensure_min_samples,\n",
      "\u001B[0;31mValueError\u001B[0m: Found array with 0 sample(s) (shape=(0, 50176)) while a minimum of 1 is required."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "ecommerce_indices = np.random.permutation(7674)\n",
    "ecommerce_train_indices = ecommerce_indices[:6139]\n",
    "ecommerce_test_indices = ecommerce_indices[6140:]\n",
    "\n",
    "np.save(\"ecommerce_train_indices\", ecommerce_train_indices)\n",
    "np.save(\"ecommerce_test_indices\", ecommerce_test_indices)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "prices = []\n",
    "image_paths = []\n",
    "\n",
    "data_path = \"../Data/Images/\"\n",
    "with open(\"../Data/updated_ecommerce_data.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    headers = next(reader, None)\n",
    "    i = -1\n",
    "    for row in reader:\n",
    "        i += 1\n",
    "        index = row[0]\n",
    "        uniq_id = row[1]\n",
    "        msrp = int(row[4])\n",
    "        \n",
    "        image_path = data_path + uniq_id+ '_0' + '.jpg'\n",
    "        image_paths.append(image_path)\n",
    "        prices.append(int(msrp))\n",
    "\n",
    "train_indices = np.load(\"ecommerce_train_indices.npy\")\n",
    "test_indices = np.load(\"ecommerce_test_indices.npy\")\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(image_paths, prices, test_size=0.20)\n"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Black'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/44/zdx95fpn3bv669w81970ks_w0000gn/T/ipykernel_94045/961870408.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrow\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m         \u001B[0muniq_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrow\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m         \u001B[0mmsrp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrow\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m         \u001B[0mimage_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata_path\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0muniq_id\u001B[0m\u001B[0;34m+\u001B[0m \u001B[0;34m'_0'\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'.jpg'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: 'Black'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Initialize Image Generator ##\n",
    "Due to the size of our dataset (>20,000 images), we cannot read all images into memory. Thus, we write our own image generator, which is a Python generator that reads images a minibatch at a time, preprocessing them and returning the input data and price labels as input to the neural network."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def image_generator(indices, batch_size):\n",
    "\n",
    "    num_batches = int(len(indices) / batch_size)\n",
    "    \n",
    "    while True:\n",
    "        for batch_i in range(num_batches):\n",
    "            if batch_i == num_batches - 1:\n",
    "                # special case: return as many as possible\n",
    "                start_i = batch_i * batch_size\n",
    "                batch_indices = indices[start_i:]\n",
    "                \n",
    "                X = np.zeros((len(batch_indices), 224, 224, 3))\n",
    "                Y = np.zeros((len(batch_indices), 1))\n",
    "            \n",
    "            else:\n",
    "                start_i = batch_i * batch_size\n",
    "                end_i = start_i + batch_size\n",
    "\n",
    "                batch_indices = indices[start_i:end_i]\n",
    "\n",
    "                X = np.zeros((batch_size, 224, 224, 3))\n",
    "                Y = np.zeros((batch_size, 1))\n",
    "            \n",
    "            for i, index in enumerate(batch_indices):\n",
    "                img = image.load_img(image_paths[index], target_size=(224, 224))\n",
    "                X[i, :, :, :] = image.img_to_array(img)                \n",
    "                Y[i] = prices[index]\n",
    "            \n",
    "            # use vgg16 preprocessing\n",
    "            X = preprocess_input(X)\n",
    "            \n",
    "            yield (X, Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Hyperparameters ##\n",
    "\n",
    "We tune hyperparameters using grid search and random search, modifying one hyperparameter at a time while keeping the others constant."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Hyperparameters\n",
    "\n",
    "num_settings = 1\n",
    "\n",
    "hp_dropout = [0.2] * num_settings\n",
    "\n",
    "#RMSprop\n",
    "hp_lr = [0.01] * num_settings\n",
    "hp_rho = [0.9] * num_settings\n",
    "hp_epsilon = [1e-07] * num_settings\n",
    "hp_decay = [0.0] * num_settings\n",
    "\n",
    "# Number of hidden units\n",
    "hp_hidden = [256] * num_settings\n",
    "\n",
    "# Minibatch size\n",
    "hp_mbsize = [64] * num_settings\n",
    "\n",
    "num_epochs = 20"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# store the results of each setting\n",
    "train_losses = np.zeros(num_settings)\n",
    "dev_losses = np.zeros(num_settings)\n",
    "\n",
    "for setting in range(num_settings):\n",
    "    # build the VGG16 network\n",
    "    input_tensor = Input(shape=(224,224,3))\n",
    "    model = VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)\n",
    "    \n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=(model.output_shape[1:])))\n",
    "\n",
    "\n",
    "    # Output layer\n",
    "    # We do random weight intialization\n",
    "    top_model.add(Dropout(hp_dropout[setting]))\n",
    "    top_model.add(Dense(hp_hidden[setting], activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    top_model.add(Dense(1, activation='linear', name='output', kernel_initializer='glorot_uniform'))\n",
    "    \n",
    "    # add the model on top of the convolutional base\n",
    "    new_model = Model(inputs= model.input, outputs = top_model(model.output))\n",
    "\n",
    "    new_model.layers\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 17:29:55.786117: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "new_model.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 1)                 6423041   \n",
      "=================================================================\n",
      "Total params: 21,137,729\n",
      "Trainable params: 21,137,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[<keras.engine.input_layer.InputLayer at 0x7f8ef156fbb0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef18274c0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef1827f40>,\n <keras.layers.pooling.MaxPooling2D at 0x7f8ef1827ca0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef190f460>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef1913220>,\n <keras.layers.pooling.MaxPooling2D at 0x7f8ef1913f40>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef191a730>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef198f5b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef19948b0>,\n <keras.layers.pooling.MaxPooling2D at 0x7f8ef1913040>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef1999190>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef199e4c0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef19a3730>,\n <keras.layers.pooling.MaxPooling2D at 0x7f8ef1994dc0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef19a7dc0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef19adac0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ef19adfa0>,\n <keras.layers.pooling.MaxPooling2D at 0x7f8ef19adfd0>,\n <keras.engine.sequential.Sequential at 0x7f8ef19a7250>]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# store the results of each setting\n",
    "train_losses = np.zeros(num_settings)\n",
    "dev_losses = np.zeros(num_settings)\n",
    "\n",
    "for setting in range(num_settings):\n",
    "    # build the VGG16 network\n",
    "    input_tensor = Input(shape=(299,299,3))\n",
    "    model = InceptionResNetV2(weights='imagenet', include_top=False, input_tensor = input_tensor)\n",
    "\n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=(model.output_shape[1:])))\n",
    "\n",
    "\n",
    "    # Output layer\n",
    "    # We do random weight intialization\n",
    "    top_model.add(Dropout(hp_dropout[setting]))\n",
    "    top_model.add(Dense(hp_hidden[setting], activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    top_model.add(Dense(1, activation='linear', name='output', kernel_initializer='glorot_uniform'))\n",
    "\n",
    "     # add the model on top of the convolutional base\n",
    "    new_model = Model(inputs= model.input, outputs = top_model(model.output))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_609 (Conv2D)             (None, 149, 149, 32) 864         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_609 (BatchN (None, 149, 149, 32) 96          conv2d_609[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_609 (Activation)     (None, 149, 149, 32) 0           batch_normalization_609[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_610 (Conv2D)             (None, 147, 147, 32) 9216        activation_609[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_610 (BatchN (None, 147, 147, 32) 96          conv2d_610[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_610 (Activation)     (None, 147, 147, 32) 0           batch_normalization_610[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_611 (Conv2D)             (None, 147, 147, 64) 18432       activation_610[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_611 (BatchN (None, 147, 147, 64) 192         conv2d_611[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_611 (Activation)     (None, 147, 147, 64) 0           batch_normalization_611[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 73, 73, 64)   0           activation_611[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_612 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_612 (BatchN (None, 73, 73, 80)   240         conv2d_612[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_612 (Activation)     (None, 73, 73, 80)   0           batch_normalization_612[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_613 (Conv2D)             (None, 71, 71, 192)  138240      activation_612[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_613 (BatchN (None, 71, 71, 192)  576         conv2d_613[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_613 (Activation)     (None, 71, 71, 192)  0           batch_normalization_613[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 35, 35, 192)  0           activation_613[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_617 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_617 (BatchN (None, 35, 35, 64)   192         conv2d_617[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_617 (Activation)     (None, 35, 35, 64)   0           batch_normalization_617[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_615 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_618 (Conv2D)             (None, 35, 35, 96)   55296       activation_617[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_615 (BatchN (None, 35, 35, 48)   144         conv2d_615[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_618 (BatchN (None, 35, 35, 96)   288         conv2d_618[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_615 (Activation)     (None, 35, 35, 48)   0           batch_normalization_615[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_618 (Activation)     (None, 35, 35, 96)   0           batch_normalization_618[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_614 (Conv2D)             (None, 35, 35, 96)   18432       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_616 (Conv2D)             (None, 35, 35, 64)   76800       activation_615[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_619 (Conv2D)             (None, 35, 35, 96)   82944       activation_618[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_620 (Conv2D)             (None, 35, 35, 64)   12288       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_614 (BatchN (None, 35, 35, 96)   288         conv2d_614[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_616 (BatchN (None, 35, 35, 64)   192         conv2d_616[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_619 (BatchN (None, 35, 35, 96)   288         conv2d_619[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_620 (BatchN (None, 35, 35, 64)   192         conv2d_620[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_614 (Activation)     (None, 35, 35, 96)   0           batch_normalization_614[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_616 (Activation)     (None, 35, 35, 64)   0           batch_normalization_616[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_619 (Activation)     (None, 35, 35, 96)   0           batch_normalization_619[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_620 (Activation)     (None, 35, 35, 64)   0           batch_normalization_620[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_614[0][0]             \n",
      "                                                                 activation_616[0][0]             \n",
      "                                                                 activation_619[0][0]             \n",
      "                                                                 activation_620[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_624 (Conv2D)             (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_624 (BatchN (None, 35, 35, 32)   96          conv2d_624[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_624 (Activation)     (None, 35, 35, 32)   0           batch_normalization_624[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_622 (Conv2D)             (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_625 (Conv2D)             (None, 35, 35, 48)   13824       activation_624[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_622 (BatchN (None, 35, 35, 32)   96          conv2d_622[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_625 (BatchN (None, 35, 35, 48)   144         conv2d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_622 (Activation)     (None, 35, 35, 32)   0           batch_normalization_622[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_625 (Activation)     (None, 35, 35, 48)   0           batch_normalization_625[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_621 (Conv2D)             (None, 35, 35, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_623 (Conv2D)             (None, 35, 35, 32)   9216        activation_622[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_626 (Conv2D)             (None, 35, 35, 64)   27648       activation_625[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_621 (BatchN (None, 35, 35, 32)   96          conv2d_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_623 (BatchN (None, 35, 35, 32)   96          conv2d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_626 (BatchN (None, 35, 35, 64)   192         conv2d_626[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_621 (Activation)     (None, 35, 35, 32)   0           batch_normalization_621[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_623 (Activation)     (None, 35, 35, 32)   0           batch_normalization_623[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_626 (Activation)     (None, 35, 35, 64)   0           batch_normalization_626[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_621[0][0]             \n",
      "                                                                 activation_623[0][0]             \n",
      "                                                                 activation_626[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_630 (Conv2D)             (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_630 (BatchN (None, 35, 35, 32)   96          conv2d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_630 (Activation)     (None, 35, 35, 32)   0           batch_normalization_630[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_628 (Conv2D)             (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 35, 35, 48)   13824       activation_630[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_628 (BatchN (None, 35, 35, 32)   96          conv2d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_631 (BatchN (None, 35, 35, 48)   144         conv2d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_628 (Activation)     (None, 35, 35, 32)   0           batch_normalization_628[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_631 (Activation)     (None, 35, 35, 48)   0           batch_normalization_631[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_627 (Conv2D)             (None, 35, 35, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)             (None, 35, 35, 32)   9216        activation_628[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)             (None, 35, 35, 64)   27648       activation_631[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_627 (BatchN (None, 35, 35, 32)   96          conv2d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_629 (BatchN (None, 35, 35, 32)   96          conv2d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_632 (BatchN (None, 35, 35, 64)   192         conv2d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_627 (Activation)     (None, 35, 35, 32)   0           batch_normalization_627[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_629 (Activation)     (None, 35, 35, 32)   0           batch_normalization_629[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_632 (Activation)     (None, 35, 35, 64)   0           batch_normalization_632[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_627[0][0]             \n",
      "                                                                 activation_629[0][0]             \n",
      "                                                                 activation_632[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_636 (Conv2D)             (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_636 (BatchN (None, 35, 35, 32)   96          conv2d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_636 (Activation)     (None, 35, 35, 32)   0           batch_normalization_636[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_634 (Conv2D)             (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)             (None, 35, 35, 48)   13824       activation_636[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_634 (BatchN (None, 35, 35, 32)   96          conv2d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_637 (BatchN (None, 35, 35, 48)   144         conv2d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_634 (Activation)     (None, 35, 35, 32)   0           batch_normalization_634[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_637 (Activation)     (None, 35, 35, 48)   0           batch_normalization_637[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 35, 35, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)             (None, 35, 35, 32)   9216        activation_634[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_638 (Conv2D)             (None, 35, 35, 64)   27648       activation_637[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_633 (BatchN (None, 35, 35, 32)   96          conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_635 (BatchN (None, 35, 35, 32)   96          conv2d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_638 (BatchN (None, 35, 35, 64)   192         conv2d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_633 (Activation)     (None, 35, 35, 32)   0           batch_normalization_633[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_635 (Activation)     (None, 35, 35, 32)   0           batch_normalization_635[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_638 (Activation)     (None, 35, 35, 64)   0           batch_normalization_638[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_633[0][0]             \n",
      "                                                                 activation_635[0][0]             \n",
      "                                                                 activation_638[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_642 (Conv2D)             (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_642 (BatchN (None, 35, 35, 32)   96          conv2d_642[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_642 (Activation)     (None, 35, 35, 32)   0           batch_normalization_642[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)             (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_643 (Conv2D)             (None, 35, 35, 48)   13824       activation_642[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_640 (BatchN (None, 35, 35, 32)   96          conv2d_640[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_643 (BatchN (None, 35, 35, 48)   144         conv2d_643[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_640 (Activation)     (None, 35, 35, 32)   0           batch_normalization_640[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_643 (Activation)     (None, 35, 35, 48)   0           batch_normalization_643[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)             (None, 35, 35, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_641 (Conv2D)             (None, 35, 35, 32)   9216        activation_640[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_644 (Conv2D)             (None, 35, 35, 64)   27648       activation_643[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_639 (BatchN (None, 35, 35, 32)   96          conv2d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_641 (BatchN (None, 35, 35, 32)   96          conv2d_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_644 (BatchN (None, 35, 35, 64)   192         conv2d_644[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_639 (Activation)     (None, 35, 35, 32)   0           batch_normalization_639[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_641 (Activation)     (None, 35, 35, 32)   0           batch_normalization_641[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_644 (Activation)     (None, 35, 35, 64)   0           batch_normalization_644[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_639[0][0]             \n",
      "                                                                 activation_641[0][0]             \n",
      "                                                                 activation_644[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_648 (Conv2D)             (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_648 (BatchN (None, 35, 35, 32)   96          conv2d_648[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_648 (Activation)     (None, 35, 35, 32)   0           batch_normalization_648[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_646 (Conv2D)             (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_649 (Conv2D)             (None, 35, 35, 48)   13824       activation_648[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_646 (BatchN (None, 35, 35, 32)   96          conv2d_646[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_649 (BatchN (None, 35, 35, 48)   144         conv2d_649[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_646 (Activation)     (None, 35, 35, 32)   0           batch_normalization_646[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_649 (Activation)     (None, 35, 35, 48)   0           batch_normalization_649[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_645 (Conv2D)             (None, 35, 35, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_647 (Conv2D)             (None, 35, 35, 32)   9216        activation_646[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_650 (Conv2D)             (None, 35, 35, 64)   27648       activation_649[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_645 (BatchN (None, 35, 35, 32)   96          conv2d_645[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_647 (BatchN (None, 35, 35, 32)   96          conv2d_647[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_650 (BatchN (None, 35, 35, 64)   192         conv2d_650[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_645 (Activation)     (None, 35, 35, 32)   0           batch_normalization_645[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_647 (Activation)     (None, 35, 35, 32)   0           batch_normalization_647[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_650 (Activation)     (None, 35, 35, 64)   0           batch_normalization_650[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_645[0][0]             \n",
      "                                                                 activation_647[0][0]             \n",
      "                                                                 activation_650[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_654 (Conv2D)             (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_654 (BatchN (None, 35, 35, 32)   96          conv2d_654[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_654 (Activation)     (None, 35, 35, 32)   0           batch_normalization_654[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_652 (Conv2D)             (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_655 (Conv2D)             (None, 35, 35, 48)   13824       activation_654[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_652 (BatchN (None, 35, 35, 32)   96          conv2d_652[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_655 (BatchN (None, 35, 35, 48)   144         conv2d_655[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_652 (Activation)     (None, 35, 35, 32)   0           batch_normalization_652[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_655 (Activation)     (None, 35, 35, 48)   0           batch_normalization_655[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_651 (Conv2D)             (None, 35, 35, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_653 (Conv2D)             (None, 35, 35, 32)   9216        activation_652[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_656 (Conv2D)             (None, 35, 35, 64)   27648       activation_655[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_651 (BatchN (None, 35, 35, 32)   96          conv2d_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_653 (BatchN (None, 35, 35, 32)   96          conv2d_653[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_656 (BatchN (None, 35, 35, 64)   192         conv2d_656[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_651 (Activation)     (None, 35, 35, 32)   0           batch_normalization_651[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_653 (Activation)     (None, 35, 35, 32)   0           batch_normalization_653[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_656 (Activation)     (None, 35, 35, 64)   0           batch_normalization_656[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_651[0][0]             \n",
      "                                                                 activation_653[0][0]             \n",
      "                                                                 activation_656[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_660 (Conv2D)             (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_660 (BatchN (None, 35, 35, 32)   96          conv2d_660[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_660 (Activation)     (None, 35, 35, 32)   0           batch_normalization_660[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_658 (Conv2D)             (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_661 (Conv2D)             (None, 35, 35, 48)   13824       activation_660[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_658 (BatchN (None, 35, 35, 32)   96          conv2d_658[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_661 (BatchN (None, 35, 35, 48)   144         conv2d_661[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_658 (Activation)     (None, 35, 35, 32)   0           batch_normalization_658[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_661 (Activation)     (None, 35, 35, 48)   0           batch_normalization_661[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_657 (Conv2D)             (None, 35, 35, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_659 (Conv2D)             (None, 35, 35, 32)   9216        activation_658[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_662 (Conv2D)             (None, 35, 35, 64)   27648       activation_661[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_657 (BatchN (None, 35, 35, 32)   96          conv2d_657[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_659 (BatchN (None, 35, 35, 32)   96          conv2d_659[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_662 (BatchN (None, 35, 35, 64)   192         conv2d_662[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_657 (Activation)     (None, 35, 35, 32)   0           batch_normalization_657[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_659 (Activation)     (None, 35, 35, 32)   0           batch_normalization_659[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_662 (Activation)     (None, 35, 35, 64)   0           batch_normalization_662[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_657[0][0]             \n",
      "                                                                 activation_659[0][0]             \n",
      "                                                                 activation_662[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_666 (Conv2D)             (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_666 (BatchN (None, 35, 35, 32)   96          conv2d_666[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_666 (Activation)     (None, 35, 35, 32)   0           batch_normalization_666[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_664 (Conv2D)             (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_667 (Conv2D)             (None, 35, 35, 48)   13824       activation_666[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_664 (BatchN (None, 35, 35, 32)   96          conv2d_664[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_667 (BatchN (None, 35, 35, 48)   144         conv2d_667[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_664 (Activation)     (None, 35, 35, 32)   0           batch_normalization_664[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_667 (Activation)     (None, 35, 35, 48)   0           batch_normalization_667[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_663 (Conv2D)             (None, 35, 35, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_665 (Conv2D)             (None, 35, 35, 32)   9216        activation_664[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_668 (Conv2D)             (None, 35, 35, 64)   27648       activation_667[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_663 (BatchN (None, 35, 35, 32)   96          conv2d_663[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_665 (BatchN (None, 35, 35, 32)   96          conv2d_665[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_668 (BatchN (None, 35, 35, 64)   192         conv2d_668[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_663 (Activation)     (None, 35, 35, 32)   0           batch_normalization_663[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_665 (Activation)     (None, 35, 35, 32)   0           batch_normalization_665[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_668 (Activation)     (None, 35, 35, 64)   0           batch_normalization_668[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_663[0][0]             \n",
      "                                                                 activation_665[0][0]             \n",
      "                                                                 activation_668[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_672 (Conv2D)             (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_672 (BatchN (None, 35, 35, 32)   96          conv2d_672[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_672 (Activation)     (None, 35, 35, 32)   0           batch_normalization_672[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_670 (Conv2D)             (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_673 (Conv2D)             (None, 35, 35, 48)   13824       activation_672[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_670 (BatchN (None, 35, 35, 32)   96          conv2d_670[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_673 (BatchN (None, 35, 35, 48)   144         conv2d_673[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_670 (Activation)     (None, 35, 35, 32)   0           batch_normalization_670[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_673 (Activation)     (None, 35, 35, 48)   0           batch_normalization_673[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_669 (Conv2D)             (None, 35, 35, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_671 (Conv2D)             (None, 35, 35, 32)   9216        activation_670[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_674 (Conv2D)             (None, 35, 35, 64)   27648       activation_673[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_669 (BatchN (None, 35, 35, 32)   96          conv2d_669[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_671 (BatchN (None, 35, 35, 32)   96          conv2d_671[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_674 (BatchN (None, 35, 35, 64)   192         conv2d_674[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_669 (Activation)     (None, 35, 35, 32)   0           batch_normalization_669[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_671 (Activation)     (None, 35, 35, 32)   0           batch_normalization_671[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_674 (Activation)     (None, 35, 35, 64)   0           batch_normalization_674[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_669[0][0]             \n",
      "                                                                 activation_671[0][0]             \n",
      "                                                                 activation_674[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_678 (Conv2D)             (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_678 (BatchN (None, 35, 35, 32)   96          conv2d_678[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_678 (Activation)     (None, 35, 35, 32)   0           batch_normalization_678[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_676 (Conv2D)             (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_679 (Conv2D)             (None, 35, 35, 48)   13824       activation_678[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_676 (BatchN (None, 35, 35, 32)   96          conv2d_676[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_679 (BatchN (None, 35, 35, 48)   144         conv2d_679[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_676 (Activation)     (None, 35, 35, 32)   0           batch_normalization_676[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_679 (Activation)     (None, 35, 35, 48)   0           batch_normalization_679[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_675 (Conv2D)             (None, 35, 35, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_677 (Conv2D)             (None, 35, 35, 32)   9216        activation_676[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_680 (Conv2D)             (None, 35, 35, 64)   27648       activation_679[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_675 (BatchN (None, 35, 35, 32)   96          conv2d_675[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_677 (BatchN (None, 35, 35, 32)   96          conv2d_677[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_680 (BatchN (None, 35, 35, 64)   192         conv2d_680[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_675 (Activation)     (None, 35, 35, 32)   0           batch_normalization_675[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_677 (Activation)     (None, 35, 35, 32)   0           batch_normalization_677[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_680 (Activation)     (None, 35, 35, 64)   0           batch_normalization_680[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_675[0][0]             \n",
      "                                                                 activation_677[0][0]             \n",
      "                                                                 activation_680[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_682 (Conv2D)             (None, 35, 35, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_682 (BatchN (None, 35, 35, 256)  768         conv2d_682[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_682 (Activation)     (None, 35, 35, 256)  0           batch_normalization_682[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_683 (Conv2D)             (None, 35, 35, 256)  589824      activation_682[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_683 (BatchN (None, 35, 35, 256)  768         conv2d_683[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_683 (Activation)     (None, 35, 35, 256)  0           batch_normalization_683[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_681 (Conv2D)             (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_684 (Conv2D)             (None, 17, 17, 384)  884736      activation_683[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_681 (BatchN (None, 17, 17, 384)  1152        conv2d_681[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_684 (BatchN (None, 17, 17, 384)  1152        conv2d_684[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_681 (Activation)     (None, 17, 17, 384)  0           batch_normalization_681[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_684 (Activation)     (None, 17, 17, 384)  0           batch_normalization_684[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 17, 17, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_681[0][0]             \n",
      "                                                                 activation_684[0][0]             \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_686 (Conv2D)             (None, 17, 17, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_686 (BatchN (None, 17, 17, 128)  384         conv2d_686[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_686 (Activation)     (None, 17, 17, 128)  0           batch_normalization_686[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_687 (Conv2D)             (None, 17, 17, 160)  143360      activation_686[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_687 (BatchN (None, 17, 17, 160)  480         conv2d_687[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_687 (Activation)     (None, 17, 17, 160)  0           batch_normalization_687[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_685 (Conv2D)             (None, 17, 17, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_688 (Conv2D)             (None, 17, 17, 192)  215040      activation_687[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_685 (BatchN (None, 17, 17, 192)  576         conv2d_685[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_688 (BatchN (None, 17, 17, 192)  576         conv2d_688[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_685 (Activation)     (None, 17, 17, 192)  0           batch_normalization_685[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_688 (Activation)     (None, 17, 17, 192)  0           batch_normalization_688[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_685[0][0]             \n",
      "                                                                 activation_688[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_690 (Conv2D)             (None, 17, 17, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_690 (BatchN (None, 17, 17, 128)  384         conv2d_690[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_690 (Activation)     (None, 17, 17, 128)  0           batch_normalization_690[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_691 (Conv2D)             (None, 17, 17, 160)  143360      activation_690[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_691 (BatchN (None, 17, 17, 160)  480         conv2d_691[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_691 (Activation)     (None, 17, 17, 160)  0           batch_normalization_691[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_689 (Conv2D)             (None, 17, 17, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_692 (Conv2D)             (None, 17, 17, 192)  215040      activation_691[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_689 (BatchN (None, 17, 17, 192)  576         conv2d_689[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_692 (BatchN (None, 17, 17, 192)  576         conv2d_692[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_689 (Activation)     (None, 17, 17, 192)  0           batch_normalization_689[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_692 (Activation)     (None, 17, 17, 192)  0           batch_normalization_692[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_689[0][0]             \n",
      "                                                                 activation_692[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_694 (Conv2D)             (None, 17, 17, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_694 (BatchN (None, 17, 17, 128)  384         conv2d_694[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_694 (Activation)     (None, 17, 17, 128)  0           batch_normalization_694[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_695 (Conv2D)             (None, 17, 17, 160)  143360      activation_694[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_695 (BatchN (None, 17, 17, 160)  480         conv2d_695[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_695 (Activation)     (None, 17, 17, 160)  0           batch_normalization_695[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_693 (Conv2D)             (None, 17, 17, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_696 (Conv2D)             (None, 17, 17, 192)  215040      activation_695[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_693 (BatchN (None, 17, 17, 192)  576         conv2d_693[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_696 (BatchN (None, 17, 17, 192)  576         conv2d_696[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_693 (Activation)     (None, 17, 17, 192)  0           batch_normalization_693[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_696 (Activation)     (None, 17, 17, 192)  0           batch_normalization_696[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_693[0][0]             \n",
      "                                                                 activation_696[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_698 (Conv2D)             (None, 17, 17, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_698 (BatchN (None, 17, 17, 128)  384         conv2d_698[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_698 (Activation)     (None, 17, 17, 128)  0           batch_normalization_698[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_699 (Conv2D)             (None, 17, 17, 160)  143360      activation_698[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_699 (BatchN (None, 17, 17, 160)  480         conv2d_699[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_699 (Activation)     (None, 17, 17, 160)  0           batch_normalization_699[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_697 (Conv2D)             (None, 17, 17, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_700 (Conv2D)             (None, 17, 17, 192)  215040      activation_699[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_697 (BatchN (None, 17, 17, 192)  576         conv2d_697[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_700 (BatchN (None, 17, 17, 192)  576         conv2d_700[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_697 (Activation)     (None, 17, 17, 192)  0           batch_normalization_697[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_700 (Activation)     (None, 17, 17, 192)  0           batch_normalization_700[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_697[0][0]             \n",
      "                                                                 activation_700[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_702 (Conv2D)             (None, 17, 17, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_702 (BatchN (None, 17, 17, 128)  384         conv2d_702[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_702 (Activation)     (None, 17, 17, 128)  0           batch_normalization_702[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_703 (Conv2D)             (None, 17, 17, 160)  143360      activation_702[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_703 (BatchN (None, 17, 17, 160)  480         conv2d_703[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_703 (Activation)     (None, 17, 17, 160)  0           batch_normalization_703[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_701 (Conv2D)             (None, 17, 17, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_704 (Conv2D)             (None, 17, 17, 192)  215040      activation_703[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_701 (BatchN (None, 17, 17, 192)  576         conv2d_701[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_704 (BatchN (None, 17, 17, 192)  576         conv2d_704[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_701 (Activation)     (None, 17, 17, 192)  0           batch_normalization_701[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_704 (Activation)     (None, 17, 17, 192)  0           batch_normalization_704[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_701[0][0]             \n",
      "                                                                 activation_704[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_706 (Conv2D)             (None, 17, 17, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_706 (BatchN (None, 17, 17, 128)  384         conv2d_706[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_706 (Activation)     (None, 17, 17, 128)  0           batch_normalization_706[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_707 (Conv2D)             (None, 17, 17, 160)  143360      activation_706[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_707 (BatchN (None, 17, 17, 160)  480         conv2d_707[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_707 (Activation)     (None, 17, 17, 160)  0           batch_normalization_707[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_705 (Conv2D)             (None, 17, 17, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_708 (Conv2D)             (None, 17, 17, 192)  215040      activation_707[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_705 (BatchN (None, 17, 17, 192)  576         conv2d_705[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_708 (BatchN (None, 17, 17, 192)  576         conv2d_708[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_705 (Activation)     (None, 17, 17, 192)  0           batch_normalization_705[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_708 (Activation)     (None, 17, 17, 192)  0           batch_normalization_708[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_705[0][0]             \n",
      "                                                                 activation_708[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_710 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_710 (BatchN (None, 17, 17, 128)  384         conv2d_710[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_710 (Activation)     (None, 17, 17, 128)  0           batch_normalization_710[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_711 (Conv2D)             (None, 17, 17, 160)  143360      activation_710[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_711 (BatchN (None, 17, 17, 160)  480         conv2d_711[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_711 (Activation)     (None, 17, 17, 160)  0           batch_normalization_711[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_709 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_712 (Conv2D)             (None, 17, 17, 192)  215040      activation_711[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_709 (BatchN (None, 17, 17, 192)  576         conv2d_709[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_712 (BatchN (None, 17, 17, 192)  576         conv2d_712[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_709 (Activation)     (None, 17, 17, 192)  0           batch_normalization_709[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_712 (Activation)     (None, 17, 17, 192)  0           batch_normalization_712[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_709[0][0]             \n",
      "                                                                 activation_712[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_714 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_714 (BatchN (None, 17, 17, 128)  384         conv2d_714[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_714 (Activation)     (None, 17, 17, 128)  0           batch_normalization_714[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_715 (Conv2D)             (None, 17, 17, 160)  143360      activation_714[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_715 (BatchN (None, 17, 17, 160)  480         conv2d_715[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_715 (Activation)     (None, 17, 17, 160)  0           batch_normalization_715[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_713 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_716 (Conv2D)             (None, 17, 17, 192)  215040      activation_715[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_713 (BatchN (None, 17, 17, 192)  576         conv2d_713[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_716 (BatchN (None, 17, 17, 192)  576         conv2d_716[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_713 (Activation)     (None, 17, 17, 192)  0           batch_normalization_713[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_716 (Activation)     (None, 17, 17, 192)  0           batch_normalization_716[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_713[0][0]             \n",
      "                                                                 activation_716[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_718 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_718 (BatchN (None, 17, 17, 128)  384         conv2d_718[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_718 (Activation)     (None, 17, 17, 128)  0           batch_normalization_718[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_719 (Conv2D)             (None, 17, 17, 160)  143360      activation_718[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_719 (BatchN (None, 17, 17, 160)  480         conv2d_719[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_719 (Activation)     (None, 17, 17, 160)  0           batch_normalization_719[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_717 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_720 (Conv2D)             (None, 17, 17, 192)  215040      activation_719[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_717 (BatchN (None, 17, 17, 192)  576         conv2d_717[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_720 (BatchN (None, 17, 17, 192)  576         conv2d_720[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_717 (Activation)     (None, 17, 17, 192)  0           batch_normalization_717[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_720 (Activation)     (None, 17, 17, 192)  0           batch_normalization_720[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_717[0][0]             \n",
      "                                                                 activation_720[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_722 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_722 (BatchN (None, 17, 17, 128)  384         conv2d_722[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_722 (Activation)     (None, 17, 17, 128)  0           batch_normalization_722[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_723 (Conv2D)             (None, 17, 17, 160)  143360      activation_722[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_723 (BatchN (None, 17, 17, 160)  480         conv2d_723[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_723 (Activation)     (None, 17, 17, 160)  0           batch_normalization_723[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_721 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_724 (Conv2D)             (None, 17, 17, 192)  215040      activation_723[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_721 (BatchN (None, 17, 17, 192)  576         conv2d_721[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_724 (BatchN (None, 17, 17, 192)  576         conv2d_724[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_721 (Activation)     (None, 17, 17, 192)  0           batch_normalization_721[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_724 (Activation)     (None, 17, 17, 192)  0           batch_normalization_724[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_721[0][0]             \n",
      "                                                                 activation_724[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_726 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_726 (BatchN (None, 17, 17, 128)  384         conv2d_726[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_726 (Activation)     (None, 17, 17, 128)  0           batch_normalization_726[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_727 (Conv2D)             (None, 17, 17, 160)  143360      activation_726[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_727 (BatchN (None, 17, 17, 160)  480         conv2d_727[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_727 (Activation)     (None, 17, 17, 160)  0           batch_normalization_727[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_725 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_728 (Conv2D)             (None, 17, 17, 192)  215040      activation_727[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_725 (BatchN (None, 17, 17, 192)  576         conv2d_725[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_728 (BatchN (None, 17, 17, 192)  576         conv2d_728[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_725 (Activation)     (None, 17, 17, 192)  0           batch_normalization_725[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_728 (Activation)     (None, 17, 17, 192)  0           batch_normalization_728[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_725[0][0]             \n",
      "                                                                 activation_728[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_730 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_730 (BatchN (None, 17, 17, 128)  384         conv2d_730[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_730 (Activation)     (None, 17, 17, 128)  0           batch_normalization_730[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_731 (Conv2D)             (None, 17, 17, 160)  143360      activation_730[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_731 (BatchN (None, 17, 17, 160)  480         conv2d_731[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_731 (Activation)     (None, 17, 17, 160)  0           batch_normalization_731[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_729 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_732 (Conv2D)             (None, 17, 17, 192)  215040      activation_731[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_729 (BatchN (None, 17, 17, 192)  576         conv2d_729[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_732 (BatchN (None, 17, 17, 192)  576         conv2d_732[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_729 (Activation)     (None, 17, 17, 192)  0           batch_normalization_729[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_732 (Activation)     (None, 17, 17, 192)  0           batch_normalization_732[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_729[0][0]             \n",
      "                                                                 activation_732[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_734 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_734 (BatchN (None, 17, 17, 128)  384         conv2d_734[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_734 (Activation)     (None, 17, 17, 128)  0           batch_normalization_734[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_735 (Conv2D)             (None, 17, 17, 160)  143360      activation_734[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_735 (BatchN (None, 17, 17, 160)  480         conv2d_735[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_735 (Activation)     (None, 17, 17, 160)  0           batch_normalization_735[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_733 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_736 (Conv2D)             (None, 17, 17, 192)  215040      activation_735[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_733 (BatchN (None, 17, 17, 192)  576         conv2d_733[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_736 (BatchN (None, 17, 17, 192)  576         conv2d_736[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_733 (Activation)     (None, 17, 17, 192)  0           batch_normalization_733[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_736 (Activation)     (None, 17, 17, 192)  0           batch_normalization_736[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_733[0][0]             \n",
      "                                                                 activation_736[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_738 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_738 (BatchN (None, 17, 17, 128)  384         conv2d_738[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_738 (Activation)     (None, 17, 17, 128)  0           batch_normalization_738[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_739 (Conv2D)             (None, 17, 17, 160)  143360      activation_738[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_739 (BatchN (None, 17, 17, 160)  480         conv2d_739[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_739 (Activation)     (None, 17, 17, 160)  0           batch_normalization_739[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_737 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_740 (Conv2D)             (None, 17, 17, 192)  215040      activation_739[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_737 (BatchN (None, 17, 17, 192)  576         conv2d_737[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_740 (BatchN (None, 17, 17, 192)  576         conv2d_740[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_737 (Activation)     (None, 17, 17, 192)  0           batch_normalization_737[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_740 (Activation)     (None, 17, 17, 192)  0           batch_normalization_740[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_737[0][0]             \n",
      "                                                                 activation_740[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_742 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_742 (BatchN (None, 17, 17, 128)  384         conv2d_742[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_742 (Activation)     (None, 17, 17, 128)  0           batch_normalization_742[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_743 (Conv2D)             (None, 17, 17, 160)  143360      activation_742[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_743 (BatchN (None, 17, 17, 160)  480         conv2d_743[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_743 (Activation)     (None, 17, 17, 160)  0           batch_normalization_743[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_741 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_744 (Conv2D)             (None, 17, 17, 192)  215040      activation_743[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_741 (BatchN (None, 17, 17, 192)  576         conv2d_741[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_744 (BatchN (None, 17, 17, 192)  576         conv2d_744[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_741 (Activation)     (None, 17, 17, 192)  0           batch_normalization_741[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_744 (Activation)     (None, 17, 17, 192)  0           batch_normalization_744[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_741[0][0]             \n",
      "                                                                 activation_744[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_746 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_746 (BatchN (None, 17, 17, 128)  384         conv2d_746[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_746 (Activation)     (None, 17, 17, 128)  0           batch_normalization_746[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_747 (Conv2D)             (None, 17, 17, 160)  143360      activation_746[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_747 (BatchN (None, 17, 17, 160)  480         conv2d_747[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_747 (Activation)     (None, 17, 17, 160)  0           batch_normalization_747[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_745 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_748 (Conv2D)             (None, 17, 17, 192)  215040      activation_747[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_745 (BatchN (None, 17, 17, 192)  576         conv2d_745[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_748 (BatchN (None, 17, 17, 192)  576         conv2d_748[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_745 (Activation)     (None, 17, 17, 192)  0           batch_normalization_745[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_748 (Activation)     (None, 17, 17, 192)  0           batch_normalization_748[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_745[0][0]             \n",
      "                                                                 activation_748[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_750 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_750 (BatchN (None, 17, 17, 128)  384         conv2d_750[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_750 (Activation)     (None, 17, 17, 128)  0           batch_normalization_750[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_751 (Conv2D)             (None, 17, 17, 160)  143360      activation_750[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_751 (BatchN (None, 17, 17, 160)  480         conv2d_751[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_751 (Activation)     (None, 17, 17, 160)  0           batch_normalization_751[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_749 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_752 (Conv2D)             (None, 17, 17, 192)  215040      activation_751[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_749 (BatchN (None, 17, 17, 192)  576         conv2d_749[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_752 (BatchN (None, 17, 17, 192)  576         conv2d_752[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_749 (Activation)     (None, 17, 17, 192)  0           batch_normalization_749[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_752 (Activation)     (None, 17, 17, 192)  0           batch_normalization_752[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_749[0][0]             \n",
      "                                                                 activation_752[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_754 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_754 (BatchN (None, 17, 17, 128)  384         conv2d_754[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_754 (Activation)     (None, 17, 17, 128)  0           batch_normalization_754[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_755 (Conv2D)             (None, 17, 17, 160)  143360      activation_754[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_755 (BatchN (None, 17, 17, 160)  480         conv2d_755[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_755 (Activation)     (None, 17, 17, 160)  0           batch_normalization_755[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_753 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_756 (Conv2D)             (None, 17, 17, 192)  215040      activation_755[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_753 (BatchN (None, 17, 17, 192)  576         conv2d_753[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_756 (BatchN (None, 17, 17, 192)  576         conv2d_756[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_753 (Activation)     (None, 17, 17, 192)  0           batch_normalization_753[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_756 (Activation)     (None, 17, 17, 192)  0           batch_normalization_756[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_753[0][0]             \n",
      "                                                                 activation_756[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_758 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_758 (BatchN (None, 17, 17, 128)  384         conv2d_758[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_758 (Activation)     (None, 17, 17, 128)  0           batch_normalization_758[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_759 (Conv2D)             (None, 17, 17, 160)  143360      activation_758[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_759 (BatchN (None, 17, 17, 160)  480         conv2d_759[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_759 (Activation)     (None, 17, 17, 160)  0           batch_normalization_759[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_757 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_760 (Conv2D)             (None, 17, 17, 192)  215040      activation_759[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_757 (BatchN (None, 17, 17, 192)  576         conv2d_757[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_760 (BatchN (None, 17, 17, 192)  576         conv2d_760[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_757 (Activation)     (None, 17, 17, 192)  0           batch_normalization_757[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_760 (Activation)     (None, 17, 17, 192)  0           batch_normalization_760[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_757[0][0]             \n",
      "                                                                 activation_760[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_762 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_762 (BatchN (None, 17, 17, 128)  384         conv2d_762[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_762 (Activation)     (None, 17, 17, 128)  0           batch_normalization_762[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_763 (Conv2D)             (None, 17, 17, 160)  143360      activation_762[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_763 (BatchN (None, 17, 17, 160)  480         conv2d_763[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_763 (Activation)     (None, 17, 17, 160)  0           batch_normalization_763[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_761 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_764 (Conv2D)             (None, 17, 17, 192)  215040      activation_763[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_761 (BatchN (None, 17, 17, 192)  576         conv2d_761[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_764 (BatchN (None, 17, 17, 192)  576         conv2d_764[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_761 (Activation)     (None, 17, 17, 192)  0           batch_normalization_761[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_764 (Activation)     (None, 17, 17, 192)  0           batch_normalization_764[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_761[0][0]             \n",
      "                                                                 activation_764[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_769 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_769 (BatchN (None, 17, 17, 256)  768         conv2d_769[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_769 (Activation)     (None, 17, 17, 256)  0           batch_normalization_769[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_765 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_767 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_770 (Conv2D)             (None, 17, 17, 288)  663552      activation_769[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_765 (BatchN (None, 17, 17, 256)  768         conv2d_765[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_767 (BatchN (None, 17, 17, 256)  768         conv2d_767[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_770 (BatchN (None, 17, 17, 288)  864         conv2d_770[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_765 (Activation)     (None, 17, 17, 256)  0           batch_normalization_765[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_767 (Activation)     (None, 17, 17, 256)  0           batch_normalization_767[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_770 (Activation)     (None, 17, 17, 288)  0           batch_normalization_770[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_766 (Conv2D)             (None, 8, 8, 384)    884736      activation_765[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_768 (Conv2D)             (None, 8, 8, 288)    663552      activation_767[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_771 (Conv2D)             (None, 8, 8, 320)    829440      activation_770[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_766 (BatchN (None, 8, 8, 384)    1152        conv2d_766[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_768 (BatchN (None, 8, 8, 288)    864         conv2d_768[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_771 (BatchN (None, 8, 8, 320)    960         conv2d_771[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_766 (Activation)     (None, 8, 8, 384)    0           batch_normalization_766[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_768 (Activation)     (None, 8, 8, 288)    0           batch_normalization_768[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_771 (Activation)     (None, 8, 8, 320)    0           batch_normalization_771[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 8, 8, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_766[0][0]             \n",
      "                                                                 activation_768[0][0]             \n",
      "                                                                 activation_771[0][0]             \n",
      "                                                                 max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_773 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_773 (BatchN (None, 8, 8, 192)    576         conv2d_773[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_773 (Activation)     (None, 8, 8, 192)    0           batch_normalization_773[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_774 (Conv2D)             (None, 8, 8, 224)    129024      activation_773[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_774 (BatchN (None, 8, 8, 224)    672         conv2d_774[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_774 (Activation)     (None, 8, 8, 224)    0           batch_normalization_774[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_772 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_775 (Conv2D)             (None, 8, 8, 256)    172032      activation_774[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_772 (BatchN (None, 8, 8, 192)    576         conv2d_772[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_775 (BatchN (None, 8, 8, 256)    768         conv2d_775[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_772 (Activation)     (None, 8, 8, 192)    0           batch_normalization_772[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_775 (Activation)     (None, 8, 8, 256)    0           batch_normalization_775[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_772[0][0]             \n",
      "                                                                 activation_775[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_777 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_777 (BatchN (None, 8, 8, 192)    576         conv2d_777[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_777 (Activation)     (None, 8, 8, 192)    0           batch_normalization_777[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_778 (Conv2D)             (None, 8, 8, 224)    129024      activation_777[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_778 (BatchN (None, 8, 8, 224)    672         conv2d_778[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_778 (Activation)     (None, 8, 8, 224)    0           batch_normalization_778[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_776 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_779 (Conv2D)             (None, 8, 8, 256)    172032      activation_778[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_776 (BatchN (None, 8, 8, 192)    576         conv2d_776[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_779 (BatchN (None, 8, 8, 256)    768         conv2d_779[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_776 (Activation)     (None, 8, 8, 192)    0           batch_normalization_776[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_779 (Activation)     (None, 8, 8, 256)    0           batch_normalization_779[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_776[0][0]             \n",
      "                                                                 activation_779[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_781 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_781 (BatchN (None, 8, 8, 192)    576         conv2d_781[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_781 (Activation)     (None, 8, 8, 192)    0           batch_normalization_781[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_782 (Conv2D)             (None, 8, 8, 224)    129024      activation_781[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_782 (BatchN (None, 8, 8, 224)    672         conv2d_782[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_782 (Activation)     (None, 8, 8, 224)    0           batch_normalization_782[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_780 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_783 (Conv2D)             (None, 8, 8, 256)    172032      activation_782[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_780 (BatchN (None, 8, 8, 192)    576         conv2d_780[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_783 (BatchN (None, 8, 8, 256)    768         conv2d_783[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_780 (Activation)     (None, 8, 8, 192)    0           batch_normalization_780[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_783 (Activation)     (None, 8, 8, 256)    0           batch_normalization_783[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_780[0][0]             \n",
      "                                                                 activation_783[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_785 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_785 (BatchN (None, 8, 8, 192)    576         conv2d_785[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_785 (Activation)     (None, 8, 8, 192)    0           batch_normalization_785[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_786 (Conv2D)             (None, 8, 8, 224)    129024      activation_785[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_786 (BatchN (None, 8, 8, 224)    672         conv2d_786[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_786 (Activation)     (None, 8, 8, 224)    0           batch_normalization_786[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_784 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_787 (Conv2D)             (None, 8, 8, 256)    172032      activation_786[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_784 (BatchN (None, 8, 8, 192)    576         conv2d_784[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_787 (BatchN (None, 8, 8, 256)    768         conv2d_787[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_784 (Activation)     (None, 8, 8, 192)    0           batch_normalization_784[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_787 (Activation)     (None, 8, 8, 256)    0           batch_normalization_787[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_784[0][0]             \n",
      "                                                                 activation_787[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_789 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_789 (BatchN (None, 8, 8, 192)    576         conv2d_789[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_789 (Activation)     (None, 8, 8, 192)    0           batch_normalization_789[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_790 (Conv2D)             (None, 8, 8, 224)    129024      activation_789[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_790 (BatchN (None, 8, 8, 224)    672         conv2d_790[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_790 (Activation)     (None, 8, 8, 224)    0           batch_normalization_790[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_788 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_791 (Conv2D)             (None, 8, 8, 256)    172032      activation_790[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_788 (BatchN (None, 8, 8, 192)    576         conv2d_788[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_791 (BatchN (None, 8, 8, 256)    768         conv2d_791[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_788 (Activation)     (None, 8, 8, 192)    0           batch_normalization_788[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_791 (Activation)     (None, 8, 8, 256)    0           batch_normalization_791[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_788[0][0]             \n",
      "                                                                 activation_791[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_793 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_793 (BatchN (None, 8, 8, 192)    576         conv2d_793[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_793 (Activation)     (None, 8, 8, 192)    0           batch_normalization_793[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_794 (Conv2D)             (None, 8, 8, 224)    129024      activation_793[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_794 (BatchN (None, 8, 8, 224)    672         conv2d_794[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_794 (Activation)     (None, 8, 8, 224)    0           batch_normalization_794[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_792 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_795 (Conv2D)             (None, 8, 8, 256)    172032      activation_794[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_792 (BatchN (None, 8, 8, 192)    576         conv2d_792[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_795 (BatchN (None, 8, 8, 256)    768         conv2d_795[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_792 (Activation)     (None, 8, 8, 192)    0           batch_normalization_792[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_795 (Activation)     (None, 8, 8, 256)    0           batch_normalization_795[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_792[0][0]             \n",
      "                                                                 activation_795[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_797 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_797 (BatchN (None, 8, 8, 192)    576         conv2d_797[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_797 (Activation)     (None, 8, 8, 192)    0           batch_normalization_797[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_798 (Conv2D)             (None, 8, 8, 224)    129024      activation_797[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_798 (BatchN (None, 8, 8, 224)    672         conv2d_798[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_798 (Activation)     (None, 8, 8, 224)    0           batch_normalization_798[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_796 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_799 (Conv2D)             (None, 8, 8, 256)    172032      activation_798[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_796 (BatchN (None, 8, 8, 192)    576         conv2d_796[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_799 (BatchN (None, 8, 8, 256)    768         conv2d_799[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_796 (Activation)     (None, 8, 8, 192)    0           batch_normalization_796[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_799 (Activation)     (None, 8, 8, 256)    0           batch_normalization_799[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_796[0][0]             \n",
      "                                                                 activation_799[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_801 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_801 (BatchN (None, 8, 8, 192)    576         conv2d_801[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_801 (Activation)     (None, 8, 8, 192)    0           batch_normalization_801[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_802 (Conv2D)             (None, 8, 8, 224)    129024      activation_801[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_802 (BatchN (None, 8, 8, 224)    672         conv2d_802[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_802 (Activation)     (None, 8, 8, 224)    0           batch_normalization_802[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_800 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_803 (Conv2D)             (None, 8, 8, 256)    172032      activation_802[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_800 (BatchN (None, 8, 8, 192)    576         conv2d_800[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_803 (BatchN (None, 8, 8, 256)    768         conv2d_803[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_800 (Activation)     (None, 8, 8, 192)    0           batch_normalization_800[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_803 (Activation)     (None, 8, 8, 256)    0           batch_normalization_803[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_800[0][0]             \n",
      "                                                                 activation_803[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_805 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_805 (BatchN (None, 8, 8, 192)    576         conv2d_805[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_805 (Activation)     (None, 8, 8, 192)    0           batch_normalization_805[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_806 (Conv2D)             (None, 8, 8, 224)    129024      activation_805[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_806 (BatchN (None, 8, 8, 224)    672         conv2d_806[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_806 (Activation)     (None, 8, 8, 224)    0           batch_normalization_806[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_804 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_807 (Conv2D)             (None, 8, 8, 256)    172032      activation_806[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_804 (BatchN (None, 8, 8, 192)    576         conv2d_804[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_807 (BatchN (None, 8, 8, 256)    768         conv2d_807[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_804 (Activation)     (None, 8, 8, 192)    0           batch_normalization_804[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_807 (Activation)     (None, 8, 8, 256)    0           batch_normalization_807[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_804[0][0]             \n",
      "                                                                 activation_807[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 8, 8, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 8, 8, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_809 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_809 (BatchN (None, 8, 8, 192)    576         conv2d_809[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_809 (Activation)     (None, 8, 8, 192)    0           batch_normalization_809[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_810 (Conv2D)             (None, 8, 8, 224)    129024      activation_809[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_810 (BatchN (None, 8, 8, 224)    672         conv2d_810[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_810 (Activation)     (None, 8, 8, 224)    0           batch_normalization_810[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_808 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_811 (Conv2D)             (None, 8, 8, 256)    172032      activation_810[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_808 (BatchN (None, 8, 8, 192)    576         conv2d_808[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_811 (BatchN (None, 8, 8, 256)    768         conv2d_811[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_808 (Activation)     (None, 8, 8, 192)    0           batch_normalization_808[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_811 (Activation)     (None, 8, 8, 256)    0           batch_normalization_811[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 8, 8, 448)    0           activation_808[0][0]             \n",
      "                                                                 activation_811[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 8, 8, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 8, 8, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 8, 8, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 8, 8, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 8, 8, 1536)   0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 1)            25166337    conv_7b_ac[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 79,503,073\n",
      "Trainable params: 79,442,529\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[<keras.engine.input_layer.InputLayer at 0x7f8eccaab610>,\n <keras.layers.convolutional.Conv2D at 0x7f8ec2b7b580>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ed6005cd0>,\n <keras.layers.core.Activation at 0x7f8ea33aa5e0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ed5663af0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ed6098520>,\n <keras.layers.core.Activation at 0x7f8eca0637f0>,\n <keras.layers.convolutional.Conv2D at 0x7f8eba7a4100>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ebab5cac0>,\n <keras.layers.core.Activation at 0x7f8ebab4d820>,\n <keras.layers.pooling.MaxPooling2D at 0x7f8eba7a2340>,\n <keras.layers.convolutional.Conv2D at 0x7f8eba7a2220>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eba7a2d60>,\n <keras.layers.core.Activation at 0x7f8ebab5ca30>,\n <keras.layers.convolutional.Conv2D at 0x7f8eba7a2250>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eba7a7ee0>,\n <keras.layers.core.Activation at 0x7f8eba7a4c10>,\n <keras.layers.pooling.MaxPooling2D at 0x7f8eba79f160>,\n <keras.layers.convolutional.Conv2D at 0x7f8eb60892b0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ed56a2040>,\n <keras.layers.core.Activation at 0x7f8eba7a90d0>,\n <keras.layers.convolutional.Conv2D at 0x7f8eba7a9370>,\n <keras.layers.convolutional.Conv2D at 0x7f8ebab49670>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eba79f430>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eb60a90a0>,\n <keras.layers.core.Activation at 0x7f8eba7a6c10>,\n <keras.layers.core.Activation at 0x7f8eb60a9c40>,\n <keras.layers.pooling.AveragePooling2D at 0x7f8eb6092580>,\n <keras.layers.convolutional.Conv2D at 0x7f8eba7b1c70>,\n <keras.layers.convolutional.Conv2D at 0x7f8eba79fd90>,\n <keras.layers.convolutional.Conv2D at 0x7f8eb609dee0>,\n <keras.layers.convolutional.Conv2D at 0x7f8eb609a1f0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eba7a6df0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eba7b1400>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eb60887c0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eb6089b50>,\n <keras.layers.core.Activation at 0x7f8eba7a6cd0>,\n <keras.layers.core.Activation at 0x7f8eba7b13d0>,\n <keras.layers.core.Activation at 0x7f8eb60880d0>,\n <keras.layers.core.Activation at 0x7f8eb6088190>,\n <keras.layers.merge.Concatenate at 0x7f8eb609acd0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ea94b6c70>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ea94b6a60>,\n <keras.layers.core.Activation at 0x7f8ea94a0f40>,\n <keras.layers.convolutional.Conv2D at 0x7f8eb6080af0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ea94c2910>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ea94a09a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ea94c2850>,\n <keras.layers.core.Activation at 0x7f8ea94a5430>,\n <keras.layers.core.Activation at 0x7f8ea94b0760>,\n <keras.layers.convolutional.Conv2D at 0x7f8ebab3b9a0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ea94a0c40>,\n <keras.layers.convolutional.Conv2D at 0x7f8ea94c2bb0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ea94a5580>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ea94ac580>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ea94d1490>,\n <keras.layers.core.Activation at 0x7f8eb60855b0>,\n <keras.layers.core.Activation at 0x7f8ea94b6220>,\n <keras.layers.core.Activation at 0x7f8ea94d1d30>,\n <keras.layers.merge.Concatenate at 0x7f8ea94cd250>,\n <keras.layers.convolutional.Conv2D at 0x7f8eb6085f10>,\n <keras.layers.core.Lambda at 0x7f8e79450220>,\n <keras.layers.core.Activation at 0x7f8ea94c2a60>,\n <keras.layers.convolutional.Conv2D at 0x7f8ea94bc910>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ea94cde20>,\n <keras.layers.core.Activation at 0x7f8ea94b69d0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7945bbe0>,\n <keras.layers.convolutional.Conv2D at 0x7f8eb6085bb0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7945b9d0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eb60892e0>,\n <keras.layers.core.Activation at 0x7f8ea94c7ee0>,\n <keras.layers.core.Activation at 0x7f8e794643a0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79450f10>,\n <keras.layers.convolutional.Conv2D at 0x7f8ea94b0190>,\n <keras.layers.convolutional.Conv2D at 0x7f8ea94a51f0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ea94d4490>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ea94c27f0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79464b20>,\n <keras.layers.core.Activation at 0x7f8e7945b190>,\n <keras.layers.core.Activation at 0x7f8ea94a5f70>,\n <keras.layers.core.Activation at 0x7f8e79468280>,\n <keras.layers.merge.Concatenate at 0x7f8e79468910>,\n <keras.layers.convolutional.Conv2D at 0x7f8ea94d1c10>,\n <keras.layers.core.Lambda at 0x7f8e79464370>,\n <keras.layers.core.Activation at 0x7f8e794685e0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7946de50>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7955a970>,\n <keras.layers.core.Activation at 0x7f8e7956d0d0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79468940>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79561c70>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79484f40>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e795689a0>,\n <keras.layers.core.Activation at 0x7f8e79477190>,\n <keras.layers.core.Activation at 0x7f8e7947b6a0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79477610>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7947bd00>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79574e50>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79450f40>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79484be0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e795682b0>,\n <keras.layers.core.Activation at 0x7f8ea94a0670>,\n <keras.layers.core.Activation at 0x7f8e79484910>,\n <keras.layers.core.Activation at 0x7f8e79568f10>,\n <keras.layers.merge.Concatenate at 0x7f8e79578220>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79466af0>,\n <keras.layers.core.Lambda at 0x7f8e79586760>,\n <keras.layers.core.Activation at 0x7f8e79586fd0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79484670>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7947b970>,\n <keras.layers.core.Activation at 0x7f8e79468820>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79594eb0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79463a00>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7958ff10>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e794669a0>,\n <keras.layers.core.Activation at 0x7f8e7957f160>,\n <keras.layers.core.Activation at 0x7f8e7947b250>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7957f310>,\n <keras.layers.convolutional.Conv2D at 0x7f8e797ca2e0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79464e20>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79594670>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e797cae20>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e797c21f0>,\n <keras.layers.core.Activation at 0x7f8e79578df0>,\n <keras.layers.core.Activation at 0x7f8e79574f10>,\n <keras.layers.core.Activation at 0x7f8eba7a9e50>,\n <keras.layers.merge.Concatenate at 0x7f8e797ce8b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79578310>,\n <keras.layers.core.Lambda at 0x7f8e7946d670>,\n <keras.layers.core.Activation at 0x7f8e7947bf40>,\n <keras.layers.convolutional.Conv2D at 0x7f8e797eda90>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79894370>,\n <keras.layers.core.Activation at 0x7f8e797ed670>,\n <keras.layers.convolutional.Conv2D at 0x7f8e797e1ee0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e797fb130>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e797e1eb0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e797f5670>,\n <keras.layers.core.Activation at 0x7f8e797deac0>,\n <keras.layers.core.Activation at 0x7f8e798a1160>,\n <keras.layers.convolutional.Conv2D at 0x7f8e797d8d00>,\n <keras.layers.convolutional.Conv2D at 0x7f8e797ed2e0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e798a1ca0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e797d5af0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e797e82b0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e798a1e20>,\n <keras.layers.core.Activation at 0x7f8e797d34c0>,\n <keras.layers.core.Activation at 0x7f8e797ed3a0>,\n <keras.layers.core.Activation at 0x7f8e798ad370>,\n <keras.layers.merge.Concatenate at 0x7f8e797fba60>,\n <keras.layers.convolutional.Conv2D at 0x7f8e797d3a60>,\n <keras.layers.core.Lambda at 0x7f8e798a1130>,\n <keras.layers.core.Activation at 0x7f8e798bcd60>,\n <keras.layers.convolutional.Conv2D at 0x7f8e798cc430>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e798c1310>,\n <keras.layers.core.Activation at 0x7f8e798a1fd0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e798ad700>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79894400>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e798c0f70>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e798a1370>,\n <keras.layers.core.Activation at 0x7f8e798ad8b0>,\n <keras.layers.core.Activation at 0x7f8e797de1f0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e798bc3d0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e798c11f0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e797ce8e0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e798bce50>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e799425b0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e797ce9d0>,\n <keras.layers.core.Activation at 0x7f8e7989b7c0>,\n <keras.layers.core.Activation at 0x7f8e798c1dc0>,\n <keras.layers.core.Activation at 0x7f8e798bcd90>,\n <keras.layers.merge.Concatenate at 0x7f8e797ce790>,\n <keras.layers.convolutional.Conv2D at 0x7f8e798a87f0>,\n <keras.layers.core.Lambda at 0x7f8e7994eee0>,\n <keras.layers.core.Activation at 0x7f8e79949cd0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7995e880>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79969c40>,\n <keras.layers.core.Activation at 0x7f8e799504c0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7994faf0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79975af0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e799501c0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79950e50>,\n <keras.layers.core.Activation at 0x7f8e7994ffa0>,\n <keras.layers.core.Activation at 0x7f8e79958af0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79950130>,\n <keras.layers.convolutional.Conv2D at 0x7f8e799589d0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79975d90>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7994f130>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7995e760>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79a12670>,\n <keras.layers.core.Activation at 0x7f8e797d50d0>,\n <keras.layers.core.Activation at 0x7f8e797d5070>,\n <keras.layers.core.Activation at 0x7f8e79a12f10>,\n <keras.layers.merge.Concatenate at 0x7f8e79a0d430>,\n <keras.layers.convolutional.Conv2D at 0x7f8e797ed8e0>,\n <keras.layers.core.Lambda at 0x7f8e79975460>,\n <keras.layers.core.Activation at 0x7f8e7997c070>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79a38610>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79a44eb0>,\n <keras.layers.core.Activation at 0x7f8e79a44430>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7997cf10>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79a3ec70>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79a2bbb0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79a38fa0>,\n <keras.layers.core.Activation at 0x7f8e79a26640>,\n <keras.layers.core.Activation at 0x7f8e79a44880>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79a1da90>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79a38700>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79a38220>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79a19250>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79a318b0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7995e6d0>,\n <keras.layers.core.Activation at 0x7f8e79a2b370>,\n <keras.layers.core.Activation at 0x7f8e79a26040>,\n <keras.layers.core.Activation at 0x7f8e79958b50>,\n <keras.layers.merge.Concatenate at 0x7f8ea94b6730>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79a12eb0>,\n <keras.layers.core.Lambda at 0x7f8e79a47bb0>,\n <keras.layers.core.Activation at 0x7f8e7994e250>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79ac6c10>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79ac58e0>,\n <keras.layers.core.Activation at 0x7f8e79add130>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79949580>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79addb80>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79ac3d90>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79ad9190>,\n <keras.layers.core.Activation at 0x7f8e79abee50>,\n <keras.layers.core.Activation at 0x7f8e79ac1f40>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79abe460>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79ac1b50>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79a47070>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79abee80>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79ac12e0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79ad91f0>,\n <keras.layers.core.Activation at 0x7f8e79a19d90>,\n <keras.layers.core.Activation at 0x7f8e79ac3760>,\n <keras.layers.core.Activation at 0x7f8e79ad9d90>,\n <keras.layers.merge.Concatenate at 0x7f8e79aec070>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79958040>,\n <keras.layers.core.Lambda at 0x7f8e79af7a30>,\n <keras.layers.core.Activation at 0x7f8e79ae2070>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79bca670>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79bca460>,\n <keras.layers.core.Activation at 0x7f8e79bb6a90>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79bafd00>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79bd46a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79bb6970>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79bce5e0>,\n <keras.layers.core.Activation at 0x7f8e79baf2b0>,\n <keras.layers.core.Activation at 0x7f8e79bca220>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79aecbe0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79bbb100>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79bd45b0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79af72e0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79bbbc70>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79ad91c0>,\n <keras.layers.core.Activation at 0x7f8e79aecc40>,\n <keras.layers.core.Activation at 0x7f8e79af0df0>,\n <keras.layers.core.Activation at 0x7f8e79aec250>,\n <keras.layers.merge.Concatenate at 0x7f8e79bbb910>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79addca0>,\n <keras.layers.core.Lambda at 0x7f8e797d51f0>,\n <keras.layers.core.Activation at 0x7f8e79ac1580>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79bbbb50>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79bc6730>,\n <keras.layers.core.Activation at 0x7f8e79bdc2b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79be4d60>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79ad2a30>,\n <keras.layers.core.Activation at 0x7f8e79bdc490>,\n <keras.layers.convolutional.Conv2D at 0x7f8ea94a01f0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a92f130>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79ac6580>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79be41c0>,\n <keras.layers.core.Activation at 0x7f8e79bab370>,\n <keras.layers.core.Activation at 0x7f8e79ac63d0>,\n <keras.layers.pooling.MaxPooling2D at 0x7f8e7a933790>,\n <keras.layers.merge.Concatenate at 0x7f8e7a9334f0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a933130>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7a94fa00>,\n <keras.layers.core.Activation at 0x7f8e7a933f10>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a94a820>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7a93fc40>,\n <keras.layers.core.Activation at 0x7f8e7a94f430>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79ad9be0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a95cd30>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79bc6880>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7a95c5b0>,\n <keras.layers.core.Activation at 0x7f8e7a9373a0>,\n <keras.layers.core.Activation at 0x7f8e7a933670>,\n <keras.layers.merge.Concatenate at 0x7f8e7a9699d0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a93fa00>,\n <keras.layers.core.Lambda at 0x7f8e7a969be0>,\n <keras.layers.core.Activation at 0x7f8e7a963670>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a969d90>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7a986ac0>,\n <keras.layers.core.Activation at 0x7f8e7a978b80>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a986040>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7a96dfa0>,\n <keras.layers.core.Activation at 0x7f8e7a986c10>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a9788b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a98b730>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7a96db20>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7a98b850>,\n <keras.layers.core.Activation at 0x7f8e7a94ab50>,\n <keras.layers.core.Activation at 0x7f8e7a94a2b0>,\n <keras.layers.merge.Concatenate at 0x7f8e7a933100>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a963f40>,\n <keras.layers.core.Lambda at 0x7f8e79969940>,\n <keras.layers.core.Activation at 0x7f8e7a9877c0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a94aee0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7a996250>,\n <keras.layers.core.Activation at 0x7f8e79ac1940>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a99e580>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79961eb0>,\n <keras.layers.core.Activation at 0x7f8e7a9a0190>,\n <keras.layers.convolutional.Conv2D at 0x7f8e79a3e400>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a99e520>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79ad9df0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7a9a4b80>,\n <keras.layers.core.Activation at 0x7f8e7a9877f0>,\n <keras.layers.core.Activation at 0x7f8e7bcab070>,\n <keras.layers.merge.Concatenate at 0x7f8e7bcabac0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a969490>,\n <keras.layers.core.Lambda at 0x7f8e7a9ab910>,\n <keras.layers.core.Activation at 0x7f8e7a9aba30>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7bcabaf0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7bcc7f40>,\n <keras.layers.core.Activation at 0x7f8e7bcbbca0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7bcc0d60>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7bcabc40>,\n <keras.layers.core.Activation at 0x7f8e7bcc7970>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7bcbb610>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7bccad00>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79ac1190>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7bcca9d0>,\n <keras.layers.core.Activation at 0x7f8e7a99e7c0>,\n <keras.layers.core.Activation at 0x7f8e7bce50d0>,\n <keras.layers.merge.Concatenate at 0x7f8e7bce5430>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a9abbe0>,\n <keras.layers.core.Lambda at 0x7f8e7bcca460>,\n <keras.layers.core.Activation at 0x7f8e7bccab80>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7bce5310>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7c293be0>,\n <keras.layers.core.Activation at 0x7f8e7c293df0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7c299580>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7c299430>,\n <keras.layers.core.Activation at 0x7f8e7c2ab5b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7c2939d0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7c2aba00>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7c28d0a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7c2ab3d0>,\n <keras.layers.core.Activation at 0x7f8e7bcc02b0>,\n <keras.layers.core.Activation at 0x7f8e7bccadc0>,\n <keras.layers.merge.Concatenate at 0x7f8e7bcc02e0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7bce13a0>,\n <keras.layers.core.Lambda at 0x7f8e7bcd8c40>,\n <keras.layers.core.Activation at 0x7f8e7c2abd30>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7bcc76d0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7a937f40>,\n <keras.layers.core.Activation at 0x7f8e7a958040>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7c2b46d0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7bcd89d0>,\n <keras.layers.core.Activation at 0x7f8e7c2b92e0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a96dd60>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a9a0df0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7a96dd90>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7c2ba580>,\n <keras.layers.core.Activation at 0x7f8e7c2a0df0>,\n <keras.layers.core.Activation at 0x7f8e7c2c71c0>,\n <keras.layers.merge.Concatenate at 0x7f8e7c2c7c10>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7bce5a30>,\n <keras.layers.core.Lambda at 0x7f8e7c2c2730>,\n <keras.layers.core.Activation at 0x7f8e7c2c2bb0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7c2c7c40>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7cca3f70>,\n <keras.layers.core.Activation at 0x7f8e7cc96fa0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7cc9aeb0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7c2b45b0>,\n <keras.layers.core.Activation at 0x7f8e7cca3ac0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a9a0e20>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7c2bcee0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7cc909d0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7ccaf0a0>,\n <keras.layers.core.Activation at 0x7f8e7bcc0880>,\n <keras.layers.core.Activation at 0x7f8e7cc90640>,\n <keras.layers.merge.Concatenate at 0x7f8e7ccc0430>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7c2c2d30>,\n <keras.layers.core.Lambda at 0x7f8e7ccc02b0>,\n <keras.layers.core.Activation at 0x7f8e7ccbc6a0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ccc0460>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7d19ed30>,\n <keras.layers.core.Activation at 0x7f8e7d19e5b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7d1a66d0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7d1a64f0>,\n <keras.layers.core.Activation at 0x7f8e7d1b4700>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7d19eb20>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7d1b4b50>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7d19e850>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7d1b4460>,\n <keras.layers.core.Activation at 0x7f8e7cc9a2e0>,\n <keras.layers.core.Activation at 0x7f8e7cc96d90>,\n <keras.layers.merge.Concatenate at 0x7f8e7cc9a940>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ccbc4f0>,\n <keras.layers.core.Lambda at 0x7f8e7c2bacd0>,\n <keras.layers.core.Activation at 0x7f8e7d1b4880>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7cca8f40>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7bcaba90>,\n <keras.layers.core.Activation at 0x7f8e7bcd8640>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7d1be820>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7d1b3a60>,\n <keras.layers.core.Activation at 0x7f8e7d1c3430>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7bcb1ac0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7d1b3dc0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7c2a02e0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7d1c6730>,\n <keras.layers.core.Activation at 0x7f8e7d1ab520>,\n <keras.layers.core.Activation at 0x7f8e7d1d1310>,\n <keras.layers.merge.Concatenate at 0x7f8e7d1d1d60>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ccc0700>,\n <keras.layers.core.Lambda at 0x7f8e7d1c5bb0>,\n <keras.layers.core.Activation at 0x7f8e7d1c5a90>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7d1d1d90>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7db88af0>,\n <keras.layers.core.Activation at 0x7f8e7db7cb80>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7d1d5430>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7d1d57c0>,\n <keras.layers.core.Activation at 0x7f8e7db88c40>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7db7c8b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7db99c40>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7d1d5b20>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7db99d60>,\n <keras.layers.core.Activation at 0x7f8e7d1c5190>,\n <keras.layers.core.Activation at 0x7f8e7dba5250>,\n <keras.layers.merge.Concatenate at 0x7f8e7dba5c40>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7d1cbf40>,\n <keras.layers.core.Lambda at 0x7f8e7db94880>,\n <keras.layers.core.Activation at 0x7f8e7d1d5040>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7dba55e0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7dbb3eb0>,\n <keras.layers.core.Activation at 0x7f8e7dbb38b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7e08a850>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7e08a190>,\n <keras.layers.core.Activation at 0x7f8e7e09c970>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7dbb3100>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7e09c610>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7db820a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7e09c670>,\n <keras.layers.core.Activation at 0x7f8e7db933a0>,\n <keras.layers.core.Activation at 0x7f8e7db99af0>,\n <keras.layers.merge.Concatenate at 0x7f8e7db8b940>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7db94670>,\n <keras.layers.core.Lambda at 0x7f8e7d1d5f10>,\n <keras.layers.core.Activation at 0x7f8e7e097f70>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7db8bc70>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7c2c7be0>,\n <keras.layers.core.Activation at 0x7f8e7ccb5a00>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7e0a29a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7e0a7880>,\n <keras.layers.core.Activation at 0x7f8e7e0a75b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7bcd8e50>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7d1c50a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7ccc0c70>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7e0ab8b0>,\n <keras.layers.core.Activation at 0x7f8e7e097220>,\n <keras.layers.core.Activation at 0x7f8e7e0bc5e0>,\n <keras.layers.merge.Concatenate at 0x7f8e7e0bc8b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7dba5160>,\n <keras.layers.core.Lambda at 0x7f8e7e0b7c70>,\n <keras.layers.core.Activation at 0x7f8e7e0b0c10>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7e0b7f10>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7ea6fc40>,\n <keras.layers.core.Activation at 0x7f8e7ea627c0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ea6f1c0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7ea6fd60>,\n <keras.layers.core.Activation at 0x7f8e7ea6fd90>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ea62a30>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ea72c40>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7e0aab50>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7ea7feb0>,\n <keras.layers.core.Activation at 0x7f8e7e0aa3d0>,\n <keras.layers.core.Activation at 0x7f8e7ea8b070>,\n <keras.layers.merge.Concatenate at 0x7f8e7ea67c70>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7e0b70d0>,\n <keras.layers.core.Lambda at 0x7f8e7ea86580>,\n <keras.layers.core.Activation at 0x7f8e7ea86910>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ea8b730>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f10db80>,\n <keras.layers.core.Activation at 0x7f8e7ea9b190>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f10a9a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f10a100>,\n <keras.layers.core.Activation at 0x7f8e7f10d5b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ea9b250>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f116d00>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7ea794c0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f1167c0>,\n <keras.layers.core.Activation at 0x7f8e7ea79550>,\n <keras.layers.core.Activation at 0x7f8e7ea7fb80>,\n <keras.layers.merge.Concatenate at 0x7f8e7ea62d90>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ea868e0>,\n <keras.layers.core.Lambda at 0x7f8e7e0b0bb0>,\n <keras.layers.core.Activation at 0x7f8e7f1156a0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ea72ee0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7db8b9a0>,\n <keras.layers.core.Activation at 0x7f8e7db99850>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f11faf0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f125f10>,\n <keras.layers.core.Activation at 0x7f8e7f125700>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7d1d5100>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f115ee0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7e097280>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f12a880>,\n <keras.layers.core.Activation at 0x7f8e7f1152b0>,\n <keras.layers.core.Activation at 0x7f8e7f139070>,\n <keras.layers.merge.Concatenate at 0x7f8e7f139a30>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ea8b9d0>,\n <keras.layers.core.Lambda at 0x7f8e7e0bca60>,\n <keras.layers.core.Activation at 0x7f8e7f12d550>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f1390a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f978d90>,\n <keras.layers.core.Activation at 0x7f8e7f13e940>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f978310>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f97bc10>,\n <keras.layers.core.Activation at 0x7f8e7f978ee0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f13eb50>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f98ae80>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f128b80>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f98aee0>,\n <keras.layers.core.Activation at 0x7f8e7f11f7f0>,\n <keras.layers.core.Activation at 0x7f8e7f9960d0>,\n <keras.layers.merge.Concatenate at 0x7f8e7f98a4c0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ea95130>,\n <keras.layers.core.Lambda at 0x7f8e7f9901f0>,\n <keras.layers.core.Activation at 0x7f8e7f9a4d30>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f996880>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f9aafa0>,\n <keras.layers.core.Activation at 0x7f8e7f99dee0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e80015220>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e8001b5e0>,\n <keras.layers.core.Activation at 0x7f8e80015df0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f9a43a0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e8001e130>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f99dac0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e80015eb0>,\n <keras.layers.core.Activation at 0x7f8e7ea95cd0>,\n <keras.layers.core.Activation at 0x7f8e7f97bac0>,\n <keras.layers.merge.Concatenate at 0x7f8e7f970d60>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f990a30>,\n <keras.layers.core.Lambda at 0x7f8e7f996ac0>,\n <keras.layers.core.Activation at 0x7f8e7e0b7a30>,\n <keras.layers.convolutional.Conv2D at 0x7f8e8002e130>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7e0b7b20>,\n <keras.layers.core.Activation at 0x7f8e7f12a970>,\n <keras.layers.convolutional.Conv2D at 0x7f8e8002e040>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7ea7fe20>,\n <keras.layers.core.Activation at 0x7f8e8002ec10>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f1281c0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e800316a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7e0b7970>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e80031310>,\n <keras.layers.core.Activation at 0x7f8e7f9a4b50>,\n <keras.layers.core.Activation at 0x7f8e800342b0>,\n <keras.layers.merge.Concatenate at 0x7f8e800312b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f98aeb0>,\n <keras.layers.core.Lambda at 0x7f8e8002c970>,\n <keras.layers.core.Activation at 0x7f8e8004c400>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7ea95610>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e8004cc70>,\n <keras.layers.core.Activation at 0x7f8e8003aeb0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e809f5700>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e80a02fa0>,\n <keras.layers.core.Activation at 0x7f8e809fa310>,\n <keras.layers.convolutional.Conv2D at 0x7f8e80031460>,\n <keras.layers.convolutional.Conv2D at 0x7f8e809fad60>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e8004c490>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e809fa520>,\n <keras.layers.core.Activation at 0x7f8e8003a910>,\n <keras.layers.core.Activation at 0x7f8e80a02970>,\n <keras.layers.merge.Concatenate at 0x7f8e80053820>,\n <keras.layers.convolutional.Conv2D at 0x7f8e8003e640>,\n <keras.layers.core.Lambda at 0x7f8e809fad90>,\n <keras.layers.core.Activation at 0x7f8e80a1c040>,\n <keras.layers.convolutional.Conv2D at 0x7f8e80a02a00>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e80a06d90>,\n <keras.layers.core.Activation at 0x7f8e80a06dc0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e80a28dc0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e8116b6a0>,\n <keras.layers.core.Activation at 0x7f8e8116bf40>,\n <keras.layers.convolutional.Conv2D at 0x7f8e80a14220>,\n <keras.layers.convolutional.Conv2D at 0x7f8e81166460>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e80a1c760>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e81166af0>,\n <keras.layers.core.Activation at 0x7f8e80a23fa0>,\n <keras.layers.core.Activation at 0x7f8e809f5730>,\n <keras.layers.merge.Concatenate at 0x7f8e80a2de80>,\n <keras.layers.convolutional.Conv2D at 0x7f8e80a06d60>,\n <keras.layers.core.Lambda at 0x7f8e800317f0>,\n <keras.layers.core.Activation at 0x7f8e8003ee20>,\n <keras.layers.convolutional.Conv2D at 0x7f8e811797f0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e81187340>,\n <keras.layers.core.Activation at 0x7f8e81195340>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a9425b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e81173df0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e81173a00>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f13e7c0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7f970400>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e811956a0>,\n <keras.layers.core.Activation at 0x7f8e80a1c1f0>,\n <keras.layers.core.Activation at 0x7f8e81177a00>,\n <keras.layers.core.Activation at 0x7f8e81179ca0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e81177790>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f12d9a0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e81d24100>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e8001be20>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e811795e0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e81d244f0>,\n <keras.layers.core.Activation at 0x7f8e800468b0>,\n <keras.layers.core.Activation at 0x7f8e8117d0a0>,\n <keras.layers.core.Activation at 0x7f8e8118f8e0>,\n <keras.layers.pooling.MaxPooling2D at 0x7f8e81d248b0>,\n <keras.layers.merge.Concatenate at 0x7f8e7a93f760>,\n <keras.layers.convolutional.Conv2D at 0x7f8e81d3e2e0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e81d3e6d0>,\n <keras.layers.core.Activation at 0x7f8e81d2ba00>,\n <keras.layers.convolutional.Conv2D at 0x7f8e81d3ea90>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e81d46b20>,\n <keras.layers.core.Activation at 0x7f8e81d46f70>,\n <keras.layers.convolutional.Conv2D at 0x7f8e80a076d0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e81d460a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e81d2b8b0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e81d37b20>,\n <keras.layers.core.Activation at 0x7f8e81d2b4c0>,\n <keras.layers.core.Activation at 0x7f8e81d46c70>,\n <keras.layers.merge.Concatenate at 0x7f8e81d4ea00>,\n <keras.layers.convolutional.Conv2D at 0x7f8e81d32b20>,\n <keras.layers.core.Lambda at 0x7f8e81d43c70>,\n <keras.layers.core.Activation at 0x7f8e827f6e20>,\n <keras.layers.convolutional.Conv2D at 0x7f8e81d248e0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eb60f8f10>,\n <keras.layers.core.Activation at 0x7f8eca03da30>,\n <keras.layers.convolutional.Conv2D at 0x7f8e99469280>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e9947cb20>,\n <keras.layers.core.Activation at 0x7f8e99460550>,\n <keras.layers.convolutional.Conv2D at 0x7f8e827f6280>,\n <keras.layers.convolutional.Conv2D at 0x7f8e9956d160>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e827f6ca0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e9946bdc0>,\n <keras.layers.core.Activation at 0x7f8e81d57310>,\n <keras.layers.core.Activation at 0x7f8e9956d550>,\n <keras.layers.merge.Concatenate at 0x7f8eb60f4fd0>,\n <keras.layers.convolutional.Conv2D at 0x7f8eba73f280>,\n <keras.layers.core.Lambda at 0x7f8ebab35670>,\n <keras.layers.core.Activation at 0x7f8eba70dfd0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7f116100>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e7e097160>,\n <keras.layers.core.Activation at 0x7f8e7a97cb20>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7a987760>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79a473a0>,\n <keras.layers.core.Activation at 0x7f8e7945b940>,\n <keras.layers.convolutional.Conv2D at 0x7f8e99455b20>,\n <keras.layers.convolutional.Conv2D at 0x7f8eb33bffd0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e81d5dd00>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e797c2250>,\n <keras.layers.core.Activation at 0x7f8e8001b0a0>,\n <keras.layers.core.Activation at 0x7f8ea3282910>,\n <keras.layers.merge.Concatenate at 0x7f8e9f461c40>,\n <keras.layers.convolutional.Conv2D at 0x7f8ea1ab8250>,\n <keras.layers.core.Lambda at 0x7f8e9e9566a0>,\n <keras.layers.core.Activation at 0x7f8e9e944280>,\n <keras.layers.convolutional.Conv2D at 0x7f8e9e956460>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e994844c0>,\n <keras.layers.core.Activation at 0x7f8e7a987790>,\n <keras.layers.convolutional.Conv2D at 0x7f8e9e9566d0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ec7014bb0>,\n <keras.layers.core.Activation at 0x7f8ec7014610>,\n <keras.layers.convolutional.Conv2D at 0x7f8e9c8671c0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ec0a8d6d0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e99cb9df0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ec1b07c70>,\n <keras.layers.core.Activation at 0x7f8e9c85c6a0>,\n <keras.layers.core.Activation at 0x7f8ebe6c87c0>,\n <keras.layers.merge.Concatenate at 0x7f8ebe6c8040>,\n <keras.layers.convolutional.Conv2D at 0x7f8ebf98e250>,\n <keras.layers.core.Lambda at 0x7f8ebd891a90>,\n <keras.layers.core.Activation at 0x7f8ebd80c520>,\n <keras.layers.convolutional.Conv2D at 0x7f8e9b7539a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ec1b07b20>,\n <keras.layers.core.Activation at 0x7f8ea94d48e0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7c2abfd0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eca039190>,\n <keras.layers.core.Activation at 0x7f8eba733130>,\n <keras.layers.convolutional.Conv2D at 0x7f8ebd80c820>,\n <keras.layers.convolutional.Conv2D at 0x7f8ebf98e460>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ebe6c8b50>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ebd7deeb0>,\n <keras.layers.core.Activation at 0x7f8e997c6fa0>,\n <keras.layers.core.Activation at 0x7f8ec1b07d60>,\n <keras.layers.merge.Concatenate at 0x7f8ebd7defa0>,\n <keras.layers.convolutional.Conv2D at 0x7f8e7e08a070>,\n <keras.layers.core.Lambda at 0x7f8ec3546b50>,\n <keras.layers.core.Activation at 0x7f8ebd7de610>,\n <keras.layers.convolutional.Conv2D at 0x7f8ebd2b67c0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ec53ea940>,\n <keras.layers.core.Activation at 0x7f8ec737a8b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ec737a6a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ebd2b6b80>,\n <keras.layers.core.Activation at 0x7f8eb8deebb0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ec3546fd0>,\n <keras.layers.convolutional.Conv2D at 0x7f8eb8dee9a0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ebd6595b0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eb8e05910>,\n <keras.layers.core.Activation at 0x7f8ebd2b6df0>,\n <keras.layers.core.Activation at 0x7f8eb8dee3a0>,\n <keras.layers.merge.Concatenate at 0x7f8ebd56a340>,\n <keras.layers.convolutional.Conv2D at 0x7f8ec7381760>,\n <keras.layers.core.Lambda at 0x7f8ec736da30>,\n <keras.layers.core.Activation at 0x7f8ec736d0d0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ec736d1c0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ebe6a1580>,\n <keras.layers.core.Activation at 0x7f8ec6e6b9a0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ec6e6b280>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ec6e66e20>,\n <keras.layers.core.Activation at 0x7f8ede3ec5e0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ec53e3dc0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ede3ec610>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8eb8dff580>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ec6e66040>,\n <keras.layers.core.Activation at 0x7f8ec6e771c0>,\n <keras.layers.core.Activation at 0x7f8ede2b1250>,\n <keras.layers.merge.Concatenate at 0x7f8ed4b63be0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ede2e73d0>,\n <keras.layers.core.Lambda at 0x7f8ec6e6b400>,\n <keras.layers.core.Activation at 0x7f8eb8dff1c0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ec6e6b910>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8e79a473d0>,\n <keras.layers.core.Activation at 0x7f8ebd6fd9d0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ebd7042b0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ed5aa1040>,\n <keras.layers.core.Activation at 0x7f8ed58a7ca0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ec736d550>,\n <keras.layers.convolutional.Conv2D at 0x7f8ede3a4580>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ec53e37f0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ed59a0760>,\n <keras.layers.core.Activation at 0x7f8ec7381340>,\n <keras.layers.core.Activation at 0x7f8ed5f35580>,\n <keras.layers.merge.Concatenate at 0x7f8ed5f35b20>,\n <keras.layers.convolutional.Conv2D at 0x7f8ed5f14910>,\n <keras.layers.core.Lambda at 0x7f8ed56925e0>,\n <keras.layers.core.Activation at 0x7f8ed56927c0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ed5ad4430>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ed56a28b0>,\n <keras.layers.core.Activation at 0x7f8ed5813640>,\n <keras.layers.convolutional.Conv2D at 0x7f8ed5813af0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ed5fb14c0>,\n <keras.layers.core.Activation at 0x7f8ed5813610>,\n <keras.layers.convolutional.Conv2D at 0x7f8ed5692d60>,\n <keras.layers.convolutional.Conv2D at 0x7f8ed5fdac10>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ed5f35bb0>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ed563a370>,\n <keras.layers.core.Activation at 0x7f8ed5ad41c0>,\n <keras.layers.core.Activation at 0x7f8ed58ae2e0>,\n <keras.layers.merge.Concatenate at 0x7f8ed58ae580>,\n <keras.layers.convolutional.Conv2D at 0x7f8ed5813a30>,\n <keras.layers.core.Lambda at 0x7f8ed5663a60>,\n <keras.layers.core.Activation at 0x7f8ed5663940>,\n <keras.layers.convolutional.Conv2D at 0x7f8ed5f70490>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ef13f15b0>,\n <keras.layers.core.Activation at 0x7f8ed561b7c0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ed56bf730>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ed6483fa0>,\n <keras.layers.core.Activation at 0x7f8ed58ea160>,\n <keras.layers.convolutional.Conv2D at 0x7f8e81d2b580>,\n <keras.layers.convolutional.Conv2D at 0x7f8ed4c3b490>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ed6483d30>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ed56bfb80>,\n <keras.layers.core.Activation at 0x7f8ed5f70d30>,\n <keras.layers.core.Activation at 0x7f8ed5f70910>,\n <keras.layers.merge.Concatenate at 0x7f8ed58752b0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ed56a2190>,\n <keras.layers.core.Lambda at 0x7f8ed58751f0>,\n <keras.layers.convolutional.Conv2D at 0x7f8ed6370850>,\n <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f8ebd896bb0>,\n <keras.layers.core.Activation at 0x7f8eba7a9400>,\n <keras.engine.sequential.Sequential at 0x7f8ebab49850>]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for setting in range(num_settings):\n",
    "    # set the first 19 layers (up to the last conv block)\n",
    "    # to non-trainable (weights will not be updated)\n",
    "    for layer in new_model.layers[:19]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # RMSprop optimizer\n",
    "    new_model.compile(loss='mean_squared_error',\n",
    "                      optimizer=optimizers.RMSprop(\n",
    "                              lr=hp_lr[setting],\n",
    "                              rho=hp_rho[setting],\n",
    "                              epsilon=hp_epsilon[setting],\n",
    "                              decay=hp_decay[setting]))\n",
    "\n",
    "    checkpoint_path = '/output/ecommerce-cnn-best.hdf5'\n",
    "\n",
    "    # keep a checkpoint\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path,\n",
    "                                monitor='val_loss',\n",
    "                                save_best_only=True,\n",
    "                                mode='min')\n",
    "\n",
    "    minibatch_size = hp_mbsize[setting]\n",
    "\n",
    "    train_steps = math.ceil(len(train_indices) / minibatch_size)\n",
    "    test_steps = math.ceil(len(test_indices) / minibatch_size)\n",
    "\n",
    "    # fine-tune the model\n",
    "    history = new_model.fit(\n",
    "        image_generator(train_indices, minibatch_size),\n",
    "        steps_per_epoch=train_steps,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=image_generator(test_indices, minibatch_size),\n",
    "        callbacks=[checkpoint])\n",
    "\n",
    "    # store the training and dev losses for the last epoch (current model)\n",
    "    train_losses[setting] = history.history['loss'][-1]\n",
    "    dev_losses[setting] = history.history['val_loss'][-1]\n",
    "\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"==========\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}